{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8fc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our framework 'fam' aka 'Feature Attribution with Measures'\n",
    "import fam\n",
    "\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222725a",
   "metadata": {},
   "source": [
    "Illustration of global feature attribution (using Riemann sum approximation) in the setting of Corollary C.3 for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 11902.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution for each feature:  tensor([0.9990, 0.9990])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model to explain\n",
    "# you need to put ... to take into account all the possible batch dimensions.\n",
    "model = lambda x: x[..., 0] + x[..., 1]\n",
    "\n",
    "# define the input space\n",
    "input_dim = 2\n",
    "input_space = [0, 1]\n",
    "\n",
    "# define the integrands for each feature to explain. This one corresponds to the integrands of Corollary C.3 in the paper.\n",
    "integrands = [lambda x, y : 2*x[..., 0] * (x[..., 1] > 0).float(), lambda x, y: 2*(x[...,0] > 0).float() * x[..., 1]]\n",
    "\n",
    "# define the attribution method\n",
    "attribution_method = fam.FeatureAttribution(model, input_dim, input_space, integrands = integrands)\n",
    "\n",
    "# define the input to explain, here the take None as we are doing global attribution\n",
    "explained_point = None\n",
    "\n",
    "# compute the attribution, choose batch_size as a divisor of N_points^(input_dim)\n",
    "attributions_tensor = torch.tensor(attribution_method.stieltjes_attribution(explained_point, is_montecarlo = False, N_points = 1000, batch_size=100))\n",
    "\n",
    "print(\"Attribution for each feature: \", torch.round(attributions_tensor * 1000) / 1000)\n",
    "# We are happy with [0.9990, 0.9990] as the model is symmetric in the two features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce71a75",
   "metadata": {},
   "source": [
    "Illustration of local feature attribution (using Riemann sum approximation) in the setting of Corollary C.4 for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1493c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 11153.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution for each feature:  tensor([ 0.9980, -0.1680])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model to explain\n",
    "# you need to put ... to take into account all the possible batch dimensions.\n",
    "model = lambda x: 2*x[..., 0] - 1.7*x[..., 1]\n",
    "\n",
    "# define the input space\n",
    "input_dim = 2\n",
    "input_space = [0, 1]\n",
    "\n",
    "# define the integrands for each feature to explain. This one corresponds to the integrands of Corollary C.3 in the paper.\n",
    "# y is the input to explain and x is the point we are integrating over.\n",
    "integrands = [lambda x, y: (x[...,0] >= y[..., 0]).float() * (x[..., 1] > 0).float(), lambda x, y : (x[..., 0] > 0).float() * (x[..., 1] >= y[..., 1]).float()]\n",
    "\n",
    "# define the attribution method\n",
    "attribution_method = fam.FeatureAttribution(model, input_dim, input_space, integrands = integrands)\n",
    "\n",
    "# define the input to explain\n",
    "explained_point = torch.tensor([0.5, 0.1])\n",
    "\n",
    "# compute the attribution, choose batch_size as a divisor of N_points^(input_dim)\n",
    "attributions_tensor = torch.tensor(attribution_method.stieltjes_attribution(explained_point, is_montecarlo = False, N_points = 1_000, batch_size=100))\n",
    "\n",
    "print(\"Attribution for each feature: \", torch.round(attributions_tensor * 1000) / 1000)\n",
    "# We are happy with [0.9980000257492065, -0.16830001771450043] as it is exactly w_j \\times x_j as in Corollary C.4, meaning:\n",
    "# 0.9980 ≈ 2 * 0.5\n",
    "# -0.1680 ≈ -1.7 * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85dbec",
   "metadata": {},
   "source": [
    "Illustration of global feature attribution (using Riemann sum approximation) in the setting of Corollary C.4 for ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6c601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 10955.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution for each feature:  tensor([-0.2870, -0.4900])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Seeding for reproducibility\n",
    "SEED = 25\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# define the model\n",
    "input_dim = 2\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# define the input space\n",
    "input_space = [0, 1]\n",
    "\n",
    "# define the integrands for each feature to explain. This one corresponds to the integrands of Corollary C.3 in the paper.\n",
    "integrands = [lambda x, y : 2*x[..., 0] * (x[..., 1] > 0).float(), lambda x, y: 2*(x[...,0] > 0).float() * x[..., 1]]\n",
    "\n",
    "# define the attribution method\n",
    "attribution_method = fam.FeatureAttribution(model, input_dim, input_space, integrands = integrands)\n",
    "\n",
    "# define the input to explain, here the take None as we are doing global attribution\n",
    "explained_point = None\n",
    "\n",
    "# compute the attribution, choose batch_size as a divisor of N_points^(input_dim)\n",
    "attributions_tensor = torch.tensor(attribution_method.stieltjes_attribution(explained_point, is_montecarlo = False, N_points = 1000, batch_size=100))\n",
    "\n",
    "print(\"Attribution for each feature: \", torch.round(attributions_tensor * 1000) / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e6d95",
   "metadata": {},
   "source": [
    "Illustration of global feature attribution (using Monte Carlo approximation with uniform density on $[0,1]$ for each feature) for ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4833eb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution for each feature:  tensor([-0.2090, -0.2090])\n"
     ]
    }
   ],
   "source": [
    "# Seeding for reproducibility\n",
    "SEED = 25\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# define the model\n",
    "input_dim = 2\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "# define the input space\n",
    "input_space = [0, 1]\n",
    "\n",
    "# integrands set to None as we use a sampler that should be overwritten if you want to use diffrent probability distributions.\n",
    "integrands = None\n",
    "\n",
    "# define the attribution method\n",
    "attribution_method = fam.FeatureAttribution(model, input_dim, input_space, integrands = integrands)\n",
    "\n",
    "# define the input to explain, here the take None as we are doing global attribution\n",
    "explained_point = None\n",
    "\n",
    "# compute the attribution, choose batch_size as a divisor of N_points^(input_dim)\n",
    "attributions_tensor = attribution_method.stieltjes_attribution(explained_point, is_montecarlo = True, N_points = 1000, batch_size=100)\n",
    "\n",
    "print(\"Attribution for each feature: \", torch.round(attributions_tensor * 1000) / 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
